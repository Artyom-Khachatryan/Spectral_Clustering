{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f5c4ae8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, n_neurons, act_func: str = 'sigmoid'):\n",
    "        self.n_neurons = n_neurons\n",
    "        self.act_func = act_func\n",
    "        self.units = None\n",
    "    def activation(self, w,X):\n",
    "        if self.act_func == 'relu':\n",
    "            return np.maximum(0, X@w)\n",
    "        if self.act_func == 'sigmoid':\n",
    "            return 1/(1+np.exp(-X@w))\n",
    "    def call(self, X, w):\n",
    "        return self.activation(w, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcc64d6c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-29T14:58:01.065399Z",
     "end_time": "2023-05-29T14:58:01.178284Z"
    }
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, n_layers, n_epox = 5, learning_rate = 0.1):\n",
    "        self.n_layers = n_layers\n",
    "        self.n_epox = n_epox\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_neurons = [7, 64, 128, 1]\n",
    "    def sigmoid(self, x, grad = False):\n",
    "        s = 1/(1+np.exp(-x))\n",
    "        if grad == True:\n",
    "            return s@(s-1)\n",
    "        else:\n",
    "            return s\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.W = []\n",
    "        for i in range(1, self.n_epox+1):\n",
    "            print(i)\n",
    "            if i ==1:\n",
    "                for j in range(1, self.n_layers+1):\n",
    "                    if j == 1:\n",
    "                        w = np.random.normal(0, 1/64, (X.shape[1], self.num_neurons[j-1]))\n",
    "                        self.W.append(w)\n",
    "                    else:\n",
    "                        w = np.random.normal(0, 1/self.num_neurons[j-1], (self.num_neurons[j-2], self.num_neurons[j-1]))\n",
    "                        self.W.append(w)\n",
    "                output = self.forward_prop(X, self.W)\n",
    "                #print(output[-1])\n",
    "                self.W = self.back_prop(X, y, output, self.W)\n",
    "            else:\n",
    "                output = self.forward_prop(X, self.W)\n",
    "                self.W = self.back_prop(X, y, output, self.W)\n",
    "            print(np.sum((self.outputs[-1]-y)**2, axis = 0)[0])#for print loss\n",
    "    def back_prop(self, X, y, output, W):\n",
    "        gradients = []\n",
    "        n_layers = len(W)\n",
    "        y = np.array(y)\n",
    "        y = np.reshape(y, (len(y), 1))\n",
    "        print(output[-1].shape)\n",
    "        # Calculate the gradient of the loss with respect to the output\n",
    "        gradient_loss = output[-1] - y\n",
    "        print(gradient_loss.shape)\n",
    "        # Backpropagate the gradients through each layer\n",
    "        gradient_back = gradient_loss\n",
    "        for i in range(n_layers, 0, -1):\n",
    "            gradient_layer = gradient_back*output[i-1]#element wise\n",
    "            gradient_back = np.dot(W[i-1], gradient_layer.T).T# * output[i-1] * (1 - output[i-1])\n",
    "            gradients.append(gradient_back)\n",
    "\n",
    "        # Update the weights using the gradients\n",
    "        for i in range(n_layers):\n",
    "            W[i] -= self.learning_rate * gradients[i-1]\n",
    "\n",
    "        return W\n",
    "            \n",
    "    def forward_prop(self, X, w): \n",
    "        self.outputs = []#save outputs\n",
    "        for i in range(1, self.n_layers+1):\n",
    "            if i == 1:\n",
    "                layer = Layer(self.num_neurons[i], 'sigmoid')\n",
    "\n",
    "                self.outputs.append(layer.call(X, w[i-1]))\n",
    "            else:\n",
    "                self.outputs.append(layer.call(self.outputs[i-2], w[i-1]))\n",
    "        return self.outputs\n",
    "    \n",
    "  \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dee7aa",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-29T14:55:42.396053Z",
     "end_time": "2023-05-29T14:55:42.411700Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4420a4d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-29T14:55:42.411700Z",
     "end_time": "2023-05-29T14:55:42.427311Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed5cba53",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-29T14:56:22.052321Z",
     "end_time": "2023-05-29T14:57:14.928173Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as  np\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = pd.read_csv(\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv\",\n",
    "    names=[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\",\n",
    "           \"Viscera weight\", \"Shell weight\", \"Age\"])\n",
    "X = data.drop('Age', axis = 1)\n",
    "y = data['Age']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y,random_state=0, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "7f8d2740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(7, 64)\n",
      "5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dot product shape mismatch, (2656, 64) vs (7, 64)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[192], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m NeuralNetwork(\u001B[38;5;241m3\u001B[39m)\n\u001B[1;32m----> 2\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[188], line 23\u001B[0m, in \u001B[0;36mNeuralNetwork.fit\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m     21\u001B[0m         \u001B[38;5;28mprint\u001B[39m(w\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m     22\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mW\u001B[38;5;241m.\u001B[39mappend(w)\n\u001B[1;32m---> 23\u001B[0m         output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward_prop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mW\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     24\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward_prop(X, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mW)\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackward(X, y, output, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mW)\n",
      "Cell \u001B[1;32mIn[188], line 45\u001B[0m, in \u001B[0;36mNeuralNetwork.forward_prop\u001B[1;34m(self, X, w)\u001B[0m\n\u001B[0;32m     43\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;241m5\u001B[39m)\n\u001B[0;32m     44\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutputs\u001B[38;5;241m.\u001B[39mappend(layer\u001B[38;5;241m.\u001B[39mcall(X, w[i\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]))\n\u001B[1;32m---> 45\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutputs\u001B[38;5;241m.\u001B[39mappend(\u001B[43mlayer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutputs\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mw\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutputs\n",
      "Cell \u001B[1;32mIn[117], line 12\u001B[0m, in \u001B[0;36mLayer.call\u001B[1;34m(self, X, w)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, w):\n\u001B[1;32m---> 12\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mactivation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mw\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[117], line 10\u001B[0m, in \u001B[0;36mLayer.activation\u001B[1;34m(self, w, X)\u001B[0m\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mmaximum(\u001B[38;5;241m0\u001B[39m, X\u001B[38;5;129m@w\u001B[39m)\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mact_func \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msigmoid\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m---> 10\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m1\u001B[39m\u001B[38;5;241m/\u001B[39m(\u001B[38;5;241m1\u001B[39m\u001B[38;5;241m+\u001B[39mnp\u001B[38;5;241m.\u001B[39mexp(\u001B[38;5;241;43m-\u001B[39;49m\u001B[43mX\u001B[49m\u001B[38;5;129;43m@w\u001B[39;49m))\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:1634\u001B[0m, in \u001B[0;36mDataFrame.__matmul__\u001B[1;34m(self, other)\u001B[0m\n\u001B[0;32m   1630\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__matmul__\u001B[39m(\u001B[38;5;28mself\u001B[39m, other: AnyArrayLike \u001B[38;5;241m|\u001B[39m DataFrame) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[0;32m   1631\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1632\u001B[0m \u001B[38;5;124;03m    Matrix multiplication using binary `@` operator in Python>=3.5.\u001B[39;00m\n\u001B[0;32m   1633\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1634\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:1603\u001B[0m, in \u001B[0;36mDataFrame.dot\u001B[1;34m(self, other)\u001B[0m\n\u001B[0;32m   1601\u001B[0m     rvals \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(other)\n\u001B[0;32m   1602\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m lvals\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m!=\u001B[39m rvals\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]:\n\u001B[1;32m-> 1603\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1604\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDot product shape mismatch, \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlvals\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m vs \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrvals\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1605\u001B[0m         )\n\u001B[0;32m   1607\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(other, DataFrame):\n\u001B[0;32m   1608\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_constructor(\n\u001B[0;32m   1609\u001B[0m         np\u001B[38;5;241m.\u001B[39mdot(lvals, rvals), index\u001B[38;5;241m=\u001B[39mleft\u001B[38;5;241m.\u001B[39mindex, columns\u001B[38;5;241m=\u001B[39mother\u001B[38;5;241m.\u001B[39mcolumns\n\u001B[0;32m   1610\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: Dot product shape mismatch, (2656, 64) vs (7, 64)"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(3)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9235a56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb91b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da44e5c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435fe861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b71db2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
